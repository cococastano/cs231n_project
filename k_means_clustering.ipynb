{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os.path\n",
    "import data_utils\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "\n",
    "# will we be using GPUs?\n",
    "USE_GPU = True\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print('Use GPU')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('Use CPU')\n",
    "    \n",
    "# float values used\n",
    "dtype = torch.float32\n",
    "# constant to control how often we print training loss\n",
    "train_batch_size = 32 # 32\n",
    "val_batch_size = 32 # 5\n",
    "print_every = int(100/train_batch_size)\n",
    "\n",
    "# number of dimensions to cluster by\n",
    "num_dims = 3\n",
    "\n",
    "# plotting stuff\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "#plt.rcParams['image.cmap'] = 'gray'\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(x):\n",
    "    # read in N, C, H, W\n",
    "    N = x.shape[0]\n",
    "    # flatten the the C * H * W images into a single vector per image\n",
    "    return x.view(N, -1)\n",
    "\n",
    "def check_accuracy(loader, model, training=False, print_out=False):\n",
    "    if training is True:\n",
    "        print('checking accuracy on validation set')\n",
    "    else:\n",
    "        print('checking accuracy on test set')   \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    # set model to evaluation mode\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X, y in loader:\n",
    "            # move to device, e.g. GPU or CPU\n",
    "            X = X.to(device=device, dtype=dtype)  \n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            scores = model(X)\n",
    "            # get locations of max in each row\n",
    "            _, preds = scores.max(1)\n",
    "            num_correct += (preds == y.squeeze(1)).sum()\n",
    "            num_samples += preds.size(0)\n",
    "        acc = float(num_correct) / num_samples\n",
    "        if print_out is not False:\n",
    "            print('got %d / %d correct (%.2f)' % (num_correct, \n",
    "                  num_samples, 100 * acc))\n",
    "    return acc  \n",
    "\n",
    "def encode_data(loader, model):\n",
    "    # set model to evaluation mode\n",
    "    model.eval()\n",
    "    dims = []\n",
    "    classes = []\n",
    "    index = 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in loader:\n",
    "            # move to device, e.g. GPU or CPU\n",
    "            X = X.to(device=device, dtype=dtype)  \n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            dims.append(np.array(model.encode(X,encode_to_n_dims=5))[0])\n",
    "            classes.append(np.array(y)[0][0])\n",
    "            index += 1\n",
    "            if index%500 == 0: print('encoding dataset', index)\n",
    "    return (dims,classes)\n",
    "\n",
    "def train_model(model, optimizer, epochs=1, return_history=False):\n",
    "    \"\"\"\n",
    "    inputs:\n",
    "    - model: a PyTorch Module giving the model to train.\n",
    "    - optimizer: an Optimizer object to train the model\n",
    "    - epochs: (optional) integer giving the number of epochs to train for\n",
    "    - return_history: will return tuple of loss, train accuracy, and \n",
    "                      validation accuracy histories\n",
    "    \n",
    "    returns: nothing, but prints model accuracies during training.\n",
    "    \"\"\"\n",
    "    # move the model parameters to CPU/GPU\n",
    "    model = model.to(device=device)\n",
    "    if return_history is not False: \n",
    "        loss_history = []\n",
    "        train_acc_history = []\n",
    "        val_acc_history = []\n",
    "    else:\n",
    "        loss_history = None\n",
    "        train_acc_history = None\n",
    "        val_acc_history = None\n",
    "    for e in range(epochs):\n",
    "        print()\n",
    "        print('TRAINING EPOCH: ',e)\n",
    "        for t, (X, y) in enumerate(loader_train):\n",
    "            # put model in training mode\n",
    "            model.train() \n",
    "            # move to device, e.g. GPU\n",
    "            X = X.to(device=device, dtype=dtype)  \n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "                        \n",
    "            scores = model(X)\n",
    "\n",
    "            loss = F.cross_entropy(scores, y.squeeze(1))\n",
    "\n",
    "            # zero gradients for the variables which the optimizer will update\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # backward pass: compute the gradient of the loss with respect to \n",
    "            # each  parameter of the model\n",
    "            loss.backward()\n",
    "\n",
    "            # update the parameters of the model using the gradients computed \n",
    "            # by the backwards pass\n",
    "            optimizer.step()\n",
    "\n",
    "            if t % print_every == 0:\n",
    "                print('iteration %d, loss = %.4f' % (t, loss.item()))\n",
    "                acc = check_accuracy(loader_val, model, \n",
    "                                     training=True, print_out=True)\n",
    "                print()\n",
    "            \n",
    "            if return_history is True: loss_history.append(loss)\n",
    "        \n",
    "        if return_history is True: \n",
    "            val_acc_history.append(acc)\n",
    "            train_acc_history.append(check_accuracy(loader_val, model, \n",
    "                                                    training=True, \n",
    "                                                    print_out=False))\n",
    "    \n",
    "    return (loss_history, train_acc_history, val_acc_history)\n",
    "  \n",
    "class OneLayerEncoder(nn.Module):\n",
    "    # just to make sure our process feeding into k-means is ok\n",
    "    def __init__(self, in_channel, channel_1, num_dims):\n",
    "        super().__init__()\n",
    "        # initialize 2D conv layer 1\n",
    "        self.c2d_1 = nn.Conv2d(in_channel, channel_1, kernel_size=5, stride=1,\n",
    "                               padding=2)\n",
    "        # initialize fully connected layers of 2D conv layers\n",
    "        self.fc_1_train = nn.Linear(im_h*im_w*channel_1, num_classes)\n",
    "        self.fc_1_encode = nn.Linear(im_h*im_w*channel_1, 100)\n",
    "        self.fc_2_encode = nn.Linear(100, num_dims)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        # forward pass conv net\n",
    "        x = F.relu(self.c2d_1(x))\n",
    "        x = flatten(x)\n",
    "        x = self.fc_1_train(x)\n",
    "        return x\n",
    "    \n",
    "    def encode(self,x):\n",
    "        # forward pass layer to encode\n",
    "        x = F.relu(self.c2d_1(x))\n",
    "        x = flatten(x)\n",
    "        x = self.fc_1_encode(x)\n",
    "        x = self.fc_2_encode(x)\n",
    "        return x\n",
    "\n",
    "class SixLayerEncoder(nn.Module):\n",
    "    def __init__(self, in_channel, channel_1, channel_2, channel_3,\n",
    "                 channel_4, num_dims):\n",
    "        super().__init__()\n",
    "        self.num_dims = num_dims\n",
    "        # initialize 2D conv layer 1\n",
    "        self.c2d_1 = nn.Conv2d(in_channel, channel_1, kernel_size=7, stride=1,\n",
    "                               padding=3)\n",
    "        # initialize 2D conv layer 2\n",
    "        self.c2d_2 = nn.Conv2d(channel_1, channel_2, kernel_size=5, stride=1,\n",
    "                               padding=2)\n",
    "        # initialize maxpool\n",
    "        self.maxpool2d_1 = nn.MaxPool2d(kernel_size=2)\n",
    "        # initialize 2D conv layer 3\n",
    "        self.c2d_3 = nn.Conv2d(channel_2, channel_3, kernel_size=3, stride=1,\n",
    "                               padding=1)\n",
    "        # initialize 2D conv layer 4\n",
    "        self.c2d_4 = nn.Conv2d(channel_3, channel_4, kernel_size=3, stride=1,\n",
    "                               padding=1)\n",
    "        # initialize maxpool\n",
    "        self.maxpool2d_2 = nn.MaxPool2d(kernel_size=2)\n",
    "        # initialize fully connected layers of 2D conv layers\n",
    "        self.fc_1 = nn.Linear(channel_4*im_h*im_w/16, 100)\n",
    "        self.fc_2_train = nn.Linear(100, num_classes)\n",
    "        self.fc_2_encode = nn.Linear(100, num_dims)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        # forward pass for 2*(conv -> relu -> conv -> relu -> pool) -> fc ->\n",
    "        # relu -> fc\n",
    "        x = F.relu(self.c2d_1(x))\n",
    "        x = F.relu(self.c2d_2(x))\n",
    "        x = self.maxpool2d_1(x)\n",
    "        x = F.relu(self.c2d_3(x))\n",
    "        x = F.relu(self.c2d_4(x))\n",
    "        x = self.maxpool2d_2(x)\n",
    "        x = flatten(x)\n",
    "        x = self.fc_1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc_2_train(x)\n",
    "        return x\n",
    "\n",
    "    def encode(self,x,encode_to_n_dims):\n",
    "        # forward pass layer to encode\n",
    "        x = F.relu(self.c2d_1(x))\n",
    "        x = F.relu(self.c2d_2(x))\n",
    "        x = self.maxpool2d_1(x)\n",
    "        x = F.relu(self.c2d_3(x))\n",
    "        x = F.relu(self.c2d_4(x))\n",
    "        x = self.maxpool2d_2(x)\n",
    "        x = flatten(x)\n",
    "        x = self.fc_1(x)\n",
    "        x = F.relu(x)\n",
    "        if encode_to_n_dims is self.num_dims:\n",
    "            x = self.fc_2_encode(x)\n",
    "        else:\n",
    "            fc_last = nn.Linear(100, encode_to_n_dims)\n",
    "            x = fc_last(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling dataset 0\n",
      "sampling dataset 1500\n",
      "sampling dataset 3000\n",
      "sampling dataset 4500\n",
      "sampling dataset 6000\n",
      "sampling dataset 7500\n",
      "sampling dataset 9000\n",
      "sampling dataset 10500\n",
      "train data shape:  (4500, 1, 176, 288)\n",
      "train labels shape:  (4500, 1)\n",
      "validation data shape:  (300, 1, 176, 288)\n",
      "validation labels shape:  (300, 1)\n",
      "test data shape:  (150, 1, 176, 288)\n",
      "test labels shape:  (150, 1)\n",
      "\n",
      "\n",
      "TRAINING EPOCH:  0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDNN_STATUS_MAPPING_ERROR",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-758511b6d649>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;31m# optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0mloss_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc_history\u001b[0m \u001b[0;34m=\u001b[0m         \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_history\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0mcheck_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_out\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-f72a580ab968>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, optimizer, epochs, return_history)\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-f72a580ab968>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;31m# forward pass for 2*(conv -> relu -> conv -> relu -> pool) -> fc ->\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0;31m# relu -> fc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc2d_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc2d_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxpool2d_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 301\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDNN_STATUS_MAPPING_ERROR"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "class_names = ['no break', 'break']  # 0 is no break and 1 is break\n",
    "frame_range = list(range(0,3))\n",
    "\n",
    "# frame_range = [0, 3, 7]\n",
    "num_classes = len(class_names)\n",
    "num_train = 1500*len(frame_range) # 3400\n",
    "num_val = 100*len(frame_range)# # 200\n",
    "num_test = 50*len(frame_range) # 188\n",
    "\n",
    "# make user provide model name to save to avoid overwriting if it exists \n",
    "# already! (mostly for me)\n",
    "# print('give model name:')\n",
    "# model_name = input()\n",
    "# model_file = model_name + '.pt'\n",
    "\n",
    "model_file = 'six_layer_encoder_v1.pt'\n",
    "\n",
    "if os.path.isfile(model_file) is False:\n",
    "    (X_train, y_train,\n",
    "     X_val, y_val, X_test, y_test) = data_utils.get_data(frame_range=frame_range,\n",
    "                                                         num_train=num_train,\n",
    "                                                         num_validation=num_val,\n",
    "                                                         num_test=num_test,\n",
    "                                                         feature_list=None,\n",
    "                                                         reshape_frames=False,\n",
    "                                                         crop_at_constr=False)\n",
    "    _, _, im_h, im_w = X_train.shape\n",
    "    print('train data shape: ', X_train.shape)\n",
    "    print('train labels shape: ', y_train.shape)\n",
    "    print('validation data shape: ', X_val.shape)\n",
    "    print('validation labels shape: ', y_val.shape)\n",
    "    print('test data shape: ', X_test.shape)\n",
    "    print('test labels shape: ', y_test.shape)\n",
    "    print()\n",
    "    \n",
    "    # create tesor objects, normalize and zero center and pass into data loaders\n",
    "    # hardcoded mean and standard deviation of pixel values\n",
    "    mean_pv, std_pv = 109.23, 99.78  # turns out its not helpful for binary data\n",
    "    X_train = torch.from_numpy(X_train)\n",
    "    y_train = torch.from_numpy(y_train)\n",
    "    X_val = torch.from_numpy(X_val)\n",
    "    y_val = torch.from_numpy(y_val)\n",
    "    X_test = torch.from_numpy(X_test)\n",
    "    y_test = torch.from_numpy(y_test)\n",
    "    # create data loader objects\n",
    "    train = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "    # arrays are already randomized so shuffle=False\n",
    "    loader_train = torch.utils.data.DataLoader(train, shuffle=True, \n",
    "                                               batch_size=train_batch_size)\n",
    "    val = torch.utils.data.TensorDataset(X_val, y_val)\n",
    "    loader_val = torch.utils.data.DataLoader(val, shuffle=True, \n",
    "                                             batch_size=val_batch_size)\n",
    "    test = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "    loader_test = torch.utils.data.DataLoader(test, shuffle=True)\n",
    "    \n",
    "    \n",
    "    learning_rate = 1e-3 # 3e-4 gave max of almost 97% on val, \n",
    "    channel_1, channel_2, channel_3, channel_4= 32, 16, 8, 4\n",
    "    model_2 =  SixLayerEncoder(in_channel=1, channel_1=channel_1,\n",
    "                               channel_2=channel_2, channel_3=channel_3,\n",
    "                               channel_4=channel_4, num_dims=num_dims)\n",
    "    # optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "    optimizer = optim.Adam(model_2.parameters(), lr=learning_rate)\n",
    "    loss_history, val_acc_history, train_acc_history = \\\n",
    "        train_model(model_2, optimizer, epochs=2, return_history=True)\n",
    "        \n",
    "    check_accuracy(loader_test, model_2, training=False, print_out=True)\n",
    "        \n",
    "    plt.subplot(2,1,1)\n",
    "    plt.plot(loss_history, '-o')\n",
    "    plt.xlabel('iteration')\n",
    "    plt.ylabel('loss')\n",
    "    plt.subplot(2,1,2)\n",
    "    plt.plot(train_acc_history, '-o')\n",
    "    plt.plot(val_acc_history, '-o')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    # save the model if its good!\n",
    "    torch.save(model_2, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training new model...\n",
      "\n",
      "TRAINING EPOCH:  0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDNN_STATUS_MAPPING_ERROR",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-a8b9ca7653a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mloss_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc_history\u001b[0m \u001b[0;34m=\u001b[0m         \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_history\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mcheck_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_out\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-f72a580ab968>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, optimizer, epochs, return_history)\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-f72a580ab968>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;31m# forward pass for 2*(conv -> relu -> conv -> relu -> pool) -> fc ->\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0;31m# relu -> fc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc2d_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc2d_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxpool2d_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 301\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDNN_STATUS_MAPPING_ERROR"
     ]
    }
   ],
   "source": [
    "def chunks(l, n):\n",
    "    \"\"\"yield successive n-sized chunks from l\"\"\"\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i + n]\n",
    "\n",
    "print('loading existing model...')\n",
    "my_model = torch.load(model_file)\n",
    "encoded_vals = []\n",
    "\n",
    "class_names = ['no break', 'break']  # 0 is no break and 1 is break\n",
    "frame_range = list(range(0,51))\n",
    "num_classes = len(class_names)\n",
    "part_frame_range = list(chunks(frame_range,2))\n",
    "for i, sub_range in enumerate(part_frame_range):\n",
    "    print()\n",
    "    print('PULLING PARTITION ', i)\n",
    "    num_train = 3400*len(sub_range) # 3400\n",
    "    num_val = 200*len(sub_range) # 200\n",
    "    num_test = 188*len(sub_range) # 188\n",
    "    (X_train, y_train,\n",
    "     X_val, y_val, X_test, y_test) = \\\n",
    "         data_utils.get_data(frame_range=sub_range,\n",
    "                             num_train=num_train,\n",
    "                             num_validation=num_val,\n",
    "                             num_test=num_test,\n",
    "                             feature_list=None,\n",
    "                             reshape_frames=False,\n",
    "                             crop_at_constr=False)\n",
    "\n",
    "    # create tesor objects, normalize and zero center and pass into data \n",
    "    #loaders\n",
    "    # hardcoded mean and standard deviation of pixel values\n",
    "    #data\n",
    "    X_train = torch.from_numpy(X_train)\n",
    "    y_train = torch.from_numpy(y_train)\n",
    "    X_val = torch.from_numpy(X_val)\n",
    "    y_val = torch.from_numpy(y_val)\n",
    "    X_test = torch.from_numpy(X_test)\n",
    "    y_test = torch.from_numpy(y_test)\n",
    "\n",
    "\n",
    "    X_all = torch.cat((X_train,X_val,X_test),0)\n",
    "    y_all = torch.cat((y_train,y_val,y_test),0)\n",
    "    all_data = torch.utils.data.TensorDataset(X_all, y_all)\n",
    "    print()\n",
    "    print('data shape: ', X_all.shape)\n",
    "    loader_all_data = torch.utils.data.DataLoader(all_data, shuffle=True)\n",
    "    # pull out encoded dims\n",
    "    dims,classes = encode_data(loader_all_data,my_model)\n",
    "\n",
    "    fig3D = plt.figure(1)  # LEO vs angle vs area\n",
    "    ax = fig3D.add_subplot(111, projection='3d')\n",
    "    for i,dim in enumerate(dims):\n",
    "        if int(classes[i]) is 1: color = 'r'\n",
    "        if int(classes[i]) is 0: color = 'b'\n",
    "        x = dim[0]\n",
    "        y = dim[1]\n",
    "        z = dim[2]\n",
    "        encoded_vals.append((x,y,z,classes[i]))\n",
    "        ax.scatter(x, y, z, c=color)\n",
    "\n",
    "    ax.set_xlabel('dimension 1')\n",
    "    ax.set_ylabel('dimension 2')\n",
    "    ax.set_ylabel('dimension 3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
